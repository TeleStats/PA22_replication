{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM9syH2yCobjLqMzxj2Gj7M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TeleStats/PA22_replication/blob/main/PA22_replication.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Replication package for for PA2022 submission \"Face detection, tracking, and classification from large-scale news archives for analysis of key political figures\""
      ],
      "metadata": {
        "id": "Qt2f0jcP_t5s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Clone repository and install requirements"
      ],
      "metadata": {
        "id": "siGkmZUFATav"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pjmkAHCo_p6-"
      },
      "outputs": [],
      "source": [
        "# Clone the repo from github and position to the main folder\n",
        "!git clone https://github.com/TeleStats/PA22_replication\n",
        "%cd PA22_replication\n",
        "!mkdir figures"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Download face detection, face features, and ground truth annotations"
      ],
      "metadata": {
        "id": "PjIyCuwNID_l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download and prepare data folder\n",
        "# This contains:\n",
        "# Download the embeddings corresponding to the individuals' models\n",
        "# Download precomputed detections and face features embeddedings\n",
        "# Download ground truth data for evaluation\n",
        "!wget --no-check-certificate www.satoh-lab.nii.ac.jp/member/agirbau/telestats/files/data.tar.gz\n",
        "!tar -xf data.tar.gz data\n",
        "!rm data.tar.gz"
      ],
      "metadata": {
        "id": "tItJ2eq2HW4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Requirements for replication package\n",
        "####Install requirements to replicate the results in google colab"
      ],
      "metadata": {
        "id": "ldRu0rzpTB_A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install project requirements\n",
        "!pip install -r requirements_colab.txt\n",
        "!pip install fiftyone"
      ],
      "metadata": {
        "id": "n2rtSmDiAMiE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Configuration\n",
        "####Specify the configuration options\n",
        "######**channel** --> news7-lv (NHK), hodost-lv (HODO Station), CNNW (CNN), FOXNEWSW (FOX), MSNBCW (MSNBC)\n",
        "######**detector** --> dfsd, mtcnn, yolo\n",
        "######**classifier** --> knn_3 (KNN), fcg_average_centroid (Centroid), fcg_average_vote (Vote), fcgNT_average_vote (for \"No Tracking\" in Table 6)\n",
        "\n"
      ],
      "metadata": {
        "id": "yIbzBBGEIvHe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#### Configuration options ####\n",
        "channel = \"CNNW\" # news7-lv (NHK), hodost-lv (HODO Station), CNNW (CNN), FOXNEWSW (FOX), MSNBCW (MSNBC)\n",
        "detector = \"yolo\"  # dfsd, mtcnn, yolo\n",
        "feats = \"resnetv1\"  # resnetv1 (Inception-resnet as backbone)\n",
        "classifier = \"fcg_average_vote\"  # knn_3, fcg_average_centroid, fcg_average_vote, fcgNT_average_vote (for \"No Tracking\" experiment in Table 6)\n",
        "models_path = \"faces_politicians\" if channel in ['news7-lv', 'hodost-lv'] else \"faces_us_individuals\""
      ],
      "metadata": {
        "id": "_pSiQL7srZ6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Run the tracking + classification part of the method\n",
        "####We already provide detections and face embeddings (previously downloaded). Run tracking and classification part to assign an ID to each detected face.\n",
        "######Please, run this code for all the different configurations, as done in the paper.\n",
        "######e.g. channel = \"CNNW\", detector = \"yolo\", classifier = \"fcg_average_vote\""
      ],
      "metadata": {
        "id": "QN_e1fwYuMtI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run classification for the specified options\n",
        "!python src/face_classifier.py train \"$channel\" --models_path data/\"$models_path\" --detector \"$detector\" --feats \"$feats\" --mod_feat \"$classifier\""
      ],
      "metadata": {
        "id": "Z2CSAk7_I6es"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Replication of Tables 3-6\n",
        "####Method performance with respect to face size"
      ],
      "metadata": {
        "id": "ayODzU-is3mp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Table 3\n",
        "# Amount of missed detections for the specified detector\n",
        "!python src/metrics.py train \"$channel\" --models_path data/\"$models_path\" --detector \"$detector\" --use_dets"
      ],
      "metadata": {
        "id": "ZozotZOtrTWF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tables 4, 5, 6\n",
        "# Run evaluation for for the specified options (detector + classifier)\n",
        "!python src/metrics.py train \"$channel\" --models_path data/\"$models_path\" --detector \"$detector\" --feats \"$feats\" --mod_feat \"$classifier\""
      ],
      "metadata": {
        "id": "umTRZmeC05aE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Replication of Figures 5-6\n",
        "####Method performance with respect to face size\n",
        "######Please, before reproducing this experiment, run classification for all channels with the following configuration:\n",
        "######**detector** = \"yolo\", **classifier** = \"fcg_average_vote\""
      ],
      "metadata": {
        "id": "qGhdANW1skQ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate dataset with fiftyone\n",
        "!python src/convert_dataset_to_fiftyone.py"
      ],
      "metadata": {
        "id": "Pa5QwBliZrMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Populate the dataset with the detections/classification of the key individuals\n",
        "!python src/convert_results_to_fiftyone.py"
      ],
      "metadata": {
        "id": "ouEYm6igap4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import fiftyone as fo\n",
        "import fiftyone.zoo as foz\n",
        "import fiftyone.brain as fob\n",
        "from fiftyone import ViewField as F\n",
        "\n",
        "print(fo.list_datasets())"
      ],
      "metadata": {
        "id": "IRT_7sqYfDRt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Run the cells below to replicate the results for figures 5-6 of the specified dataset"
      ],
      "metadata": {
        "id": "TBdO_IAPyh09"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify dataset\n",
        "dataset_orig = fo.load_dataset(channel)\n",
        "us_dataset_list = [\"CNNW\", \"FOXNEWSW\", \"MSNBCW\"]\n",
        "# Do \"evaluate_detections\" to compute iou to be able to threshold wrt iou for US data evaluation\n",
        "if dataset_orig.name in us_dataset_list:\n",
        "    dataset_orig.evaluate_detections(\"yolo-resnetv1-fcg_average_vote\", \"ground_truth\", eval_key=\"eval\", classwise=False)\n",
        "\n",
        "# For NHK and hodo station\n",
        "#years_list = [str(i) for i in range(2013, 2022)]\n",
        "years_list = [str(i) for i in range(2000, 2022)]\n",
        "view_analysis = dataset_orig.match(F(\"year\").is_in(years_list))\n",
        "\n",
        "# For US evaluation\n",
        "# Filter the detections based on the IoU threshold\n",
        "if dataset_orig.name in us_dataset_list:\n",
        "    view_analysis = view_analysis.filter_labels(\"yolo-resnetv1-fcg_average_vote\", F(\"eval_iou\") > 0.001).clone()\n",
        "\n",
        "# Generate different views depending on the bounding box sizes \n",
        "bbox_area = (\n",
        "    F(\"$metadata.width\") * F(\"bounding_box\")[2] *\n",
        "    F(\"$metadata.height\") * F(\"bounding_box\")[3]\n",
        ")\n",
        "# [very small, small, small-medium, medium, medium-large, large, very large]\n",
        "# Average bbox for NHK = 78x78, HODO = 52x52. US dataset around 135 x 135.\n",
        "# Smallest NHK = 3x3, HODO = 2x2. US = 35x35\n",
        "# Largest NHK = 258x258, HODO = 174x174. US = 390x390\n",
        "\n",
        "boxes_areas = list(map(int, list(np.asarray([8, 16, 32, 64, 96, 128, 156]) ** 2)))\n",
        "boxes_filter_list = []\n",
        "\n",
        "for i in range(len(boxes_areas)):\n",
        "    if i == 0:\n",
        "        # First case\n",
        "        boxes_filter = bbox_area <= boxes_areas[i]\n",
        "    else:\n",
        "        # Cases in the middle\n",
        "        boxes_filter = (bbox_area > boxes_areas[i-1]) & (bbox_area <= boxes_areas[i])\n",
        "\n",
        "    boxes_filter_list.append(boxes_filter)\n",
        "        \n",
        "# Last case\n",
        "boxes_filter_list.append(bbox_area > boxes_areas[-1])\n"
      ],
      "metadata": {
        "id": "9hT1vfowfL6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate views that contains only the filtered bboxes depending on size\n",
        "views_list = []\n",
        "\n",
        "for box_filter in boxes_filter_list:\n",
        "#for box_filter in [small_boxes, medium_boxes]:\n",
        "    view_filtered = (\n",
        "        view_analysis\n",
        "        .filter_labels(\"ground_truth\", box_filter)\n",
        "        .filter_labels(\"yolo-resnetv1-fcg_average_vote\", box_filter)\n",
        "        .filter_labels(\"yolo-resnetv1-fcg_average_vote\", F(\"label\") != \"-1\")\n",
        "    )\n",
        "    views_list.append(view_filtered)"
      ],
      "metadata": {
        "id": "mMBfilg8ri9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run evaluation for the generated filtered views\n",
        "results_list = []\n",
        "if dataset_orig.name in us_dataset_list:\n",
        "    iou_threshs = [0.4, 0.45, 0.5, 0.55, 0.6]\n",
        "else:\n",
        "    iou_threshs = None\n",
        "\n",
        "for view_filtered in views_list:\n",
        "    results_filtered = view_filtered.evaluate_detections(\n",
        "        \"yolo-resnetv1-fcg_average_vote\",\n",
        "        gt_field=\"ground_truth\",\n",
        "        eval_key=\"eval\",\n",
        "        compute_mAP=True,\n",
        "        iou_threshs=iou_threshs,  # For US evaluation\n",
        "    )\n",
        "\n",
        "    results_list.append(results_filtered)"
      ],
      "metadata": {
        "id": "kthZjPayrlmh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rows_df = []\n",
        "# 186**2 is for visualization purposes, representing [156-]\n",
        "for res, box_area in zip(results_list, boxes_areas + [186**2]):\n",
        "    res_map = round((max(res.mAP(), 0) * 100), 1)\n",
        "    res_f1 = round(res.metrics()['fscore'], 3)\n",
        "    box_size = int(np.sqrt(box_area))\n",
        "    rows_df.append([box_area, box_size, res_map, res_f1])\n",
        "    print(f\"mAP: {res_map}, F1: {res_f1}\")\n",
        "\n",
        "df_res = pd.DataFrame(data=rows_df, columns=['area', 'box_size', 'map', 'f1'])\n",
        "print(df_res)"
      ],
      "metadata": {
        "id": "-8S9y_9ErrR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "\n",
        "# mAP\n",
        "fig = px.line(df_res, x=\"box_size\", y=\"map\", text=\"map\", title=f\"mAP per bounding box size for {dataset_orig.name}\")\n",
        "fig.update_traces(textposition=\"bottom right\")\n",
        "\n",
        "fig.update_xaxes(\n",
        "    title=\"Bounding box size\"\n",
        ")\n",
        "fig.update_yaxes(\n",
        "    title=\"mAP\"\n",
        ")\n",
        "\n",
        "fig.write_image(f\"figures/results_map_face_size_{dataset_orig.name}.pdf\")\n",
        "fig.show()\n",
        "\n",
        "# F1 score\n",
        "fig = px.line(df_res, x=\"box_size\", y=\"f1\", text=\"f1\", title=f\"F-score per bounding box size for {dataset_orig.name}\")\n",
        "fig.update_traces(textposition=\"bottom right\")\n",
        "\n",
        "fig.update_xaxes(\n",
        "    title=\"Bounding box size\"\n",
        ")\n",
        "fig.update_yaxes(\n",
        "    title=\"F-score\"\n",
        ")\n",
        "\n",
        "fig.write_image(f\"figures/results_f1_face_size_{dataset_orig.name}.pdf\")\n",
        "fig.show()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "neW5Qojcrtu3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}