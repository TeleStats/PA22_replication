{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz\n",
    "import fiftyone.brain as fob\n",
    "from fiftyone import ViewField as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def count_dict_to_df(dataset_id: str, count_dict: dict, columns: list) -> pd.DataFrame:\n",
    "    list_to_df = []\n",
    "    for k in count_dict.keys():\n",
    "        row_df = [dataset_id, k, count_dict[k]]\n",
    "        list_to_df.append(row_df)\n",
    "        \n",
    "    df = pd.DataFrame(data=list_to_df, columns=columns)\n",
    "    return df        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CNNW', 'FOXNEWSW', 'MSNBCW', 'hodost-lv', 'news7-lv']\n"
     ]
    }
   ],
   "source": [
    "print(fo.list_datasets())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = fo.load_dataset(\"FOXNEWSW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used for dev.\n",
    "#dataset.delete_sample_field(\"embeddings\")\n",
    "#dataset.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Used for dev.\n",
    "# In case we want to delete the associated results (used during development)\n",
    "#dataset = fo.load_dataset(\"CNNW\")\n",
    "#print(dataset)\n",
    "#dataset.delete_sample_field(\"yolo-resnetv1-fcg_average_vote\")\n",
    "#print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating detections...\n",
      " 100% |███████████████| 1674/1674 [7.3s elapsed, 0s remaining, 245.9 samples/s]       \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<fiftyone.utils.eval.detection.DetectionResults at 0x7f1c7d236f10>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we don't specify the \"eval_key=eval\" it doesn't compute the ious\n",
    "dataset.evaluate_detections(\"yolo-resnetv1-fcg_average_vote\", \"ground_truth\", eval_key=\"eval\")\n",
    "#dataset.evaluate_detections(\"yolo-resnetv1-fcg_average_vote\", \"ground_truth\")\n",
    "\n",
    "#fo.utils.iou.compute_ious(dataset[\"yolo-resnetv1-fcg_average_vote\"], \"ground_truth\")\n",
    "#fo.utils.iou.compute_max_ious(dataset, \"ground_truth\", iou_attr=\"max_iou\", classwise=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session launched. Run `session.show()` to open the App in a cell output.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "window.open('http://localhost:5151/');"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# In case we want to make a view to reduce the amount of data to be shown\n",
    "view = dataset.match(F(\"year\").is_in([\"2012\"]))\n",
    "view = dataset.filter_labels(\"yolo-resnetv1-fcg_average_vote\", F(\"eval_iou\") > 0.1)\n",
    "#ep = view.to_evaluation_patches(\"eval\")\n",
    "#ep.match(F(\"iou\") > 0.9)\n",
    "#view = view.filter_labels(\"yolo-resnetv1-fcg_average_vote\", F(\"iou\") > 0.1)\n",
    "              \n",
    "# Open session in a tab\n",
    "session = fo.launch_app(view, auto=False)\n",
    "session.open_tab()\n",
    "# Open session in jupyer output\n",
    "#session = fo.launch_app(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataset by label. The problem is that the embeddings are not aware of this filtering,\n",
    "# so they can't be matched :(\n",
    "#from fiftyone import ViewField as F\n",
    "\n",
    "#dataset = fo.load_dataset(\"CNNW\").take(10)\n",
    "\n",
    "#view = dataset.filter_labels(\n",
    "#    \"yolo-resnetv1-fcg_average_vote\", F(\"label\").is_in([\"Donald_Trump\", \"Barack_Obama\"])\n",
    "#)\n",
    "\n",
    "# Get detections by ID (not label) and exclude them from the dataset\n",
    "#ids = [\n",
    "#    dataset.last()['yolo-resnetv1-fcg_average_vote'].detections[0].id,\n",
    "#]\n",
    "# view = dataset.exclude_labels(ids=ids)\n",
    "# print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating visualization...\n",
      "UMAP( verbose=True)\n",
      "Mon Jun 27 15:14:07 2022 Construct fuzzy simplicial set\n",
      "Mon Jun 27 15:14:07 2022 Finding Nearest Neighbors\n",
      "Mon Jun 27 15:14:07 2022 Building RP forest with 21 trees\n",
      "Mon Jun 27 15:14:08 2022 NN descent for 17 iterations\n",
      "\t 1  /  17\n",
      "\t 2  /  17\n",
      "\t 3  /  17\n",
      "\t 4  /  17\n",
      "\t 5  /  17\n",
      "\tStopping threshold met -- exiting after 5 iterations\n",
      "Mon Jun 27 15:14:24 2022 Finished Nearest Neighbor Search\n",
      "Mon Jun 27 15:14:27 2022 Construct embedding\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb1960d8be1e4c58bf8cf7fc6b4aa928",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs completed:   0%|            0/200 [00:00]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jun 27 15:15:18 2022 Finished embedding\n"
     ]
    }
   ],
   "source": [
    "# Load the previously produced embeddings\n",
    "import numpy as np\n",
    "\n",
    "#dataset = fo.load_dataset(\"CNNW\")\n",
    "embeddings = {i: e for i, e in zip(*dataset.values([\"id\", \"embeddings\"]))}\n",
    "\n",
    "results = fob.compute_visualization(\n",
    "    dataset, patches_field=\"yolo-resnetv1-fcg_average_vote\", embeddings=embeddings, num_dims=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example for computing the embeddings with a model from the zoo\n",
    "#dataset = fo.load_dataset(\"CNNW\").take(10)\n",
    "#dataset = fo.load_dataset(\"hodost-lv\")\n",
    "#dataset_patches = dataset.to_patches(\"ground_truth\")\n",
    "#dataset_patches = dataset.to_patches(\"yolo-resnetv1-fcg_average_vote\")\n",
    "#foz.models.list_zoo_models()\n",
    "#model = foz.load_zoo_model(\"mobilenet-v2-imagenet-torch\")\n",
    "#embs_test = dataset.compute_patch_embeddings(model, \"yolo-resnetv1-fcg_average_vote\")\n",
    "# Compute visualization\n",
    "#results = fob.compute_visualization(dataset, patches_field=\"yolo-resnetv1-fcg_average_vote\", embeddings=embs_test, seed=51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.get_classes(\"yolo-resnetv1-fcg_average_vote\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbad62a2edeb4ebfb5a072fe3a81a385",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'customdata': array(['62b5572436ba2283d6363a65', '62b5572436ba2283d6363a68',\n",
       "    …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Which \"classes\" to plot\n",
    "#classes_list = dataset.get_classes(\"yolo-resnetv1-fcg_average_vote\")\n",
    "from utils import PRIME_MINISTERS\n",
    "\n",
    "classes_list = list(set(PRIME_MINISTERS)) # Get unique classes\n",
    "classes_ignore = ['-1']\n",
    "classes_to_plot = [c for c in classes_list if c not in classes_ignore]\n",
    "# Generate scatterplot\n",
    "plot = results.visualize(\n",
    "    #labels=\"ground_truth.detections.label\",\n",
    "    #labels=\"ground_truth.label\",\n",
    "    #labels=\"yolo-resnetv1-fcg_average_vote.label\",\n",
    "    labels=\"yolo-resnetv1-fcg_average_vote.detections.label\",\n",
    "    labels_title=\"ID\",\n",
    "    classes=classes_to_plot,\n",
    "    axis_equal=True,\n",
    ")\n",
    "plot.show(height=512)\n",
    "\n",
    "session.plots.attach(plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataset\n",
    "from fiftyone import ViewField as F\n",
    "\n",
    "# Only contains detections with confidence >= 0.75\n",
    "#high_conf_view = predictions_view.filter_labels(\"yolo-resnetv1-fcg_average_vote\", F(\"confidence\") > 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating detections...\n",
      " 100% |███████████████| 1083/1083 [5.2s elapsed, 0s remaining, 228.9 samples/s]      \n",
      "Performing IoU sweep...\n",
      " 100% |███████████████| 1083/1083 [5.2s elapsed, 0s remaining, 232.3 samples/s]      \n"
     ]
    }
   ],
   "source": [
    "# Resource: https://voxel51.com/docs/fiftyone/tutorials/evaluate_detections.html\n",
    "# Evaluate the predictions in the `faster_rcnn` field of our `high_conf_view`\n",
    "# with respect to the objects in the `ground_truth` field\n",
    "dataset = fo.load_dataset(\"CNNW\")\n",
    "\n",
    "results = dataset.evaluate_detections(\n",
    "    \"yolo-resnetv1-fcg_average_vote\",\n",
    "    gt_field=\"ground_truth\",\n",
    "    eval_key=\"eval\",\n",
    "    compute_mAP=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.3283533614810003,\n",
       " 'precision': 0.3362154971732624,\n",
       " 'recall': 0.9335180055401662,\n",
       " 'fscore': 0.4943765281173594,\n",
       " 'support': 1083}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Kellyanne_Conway       0.96      0.98      0.97        66\n",
      " Hillary_Clinton       0.61      0.96      0.74        48\n",
      " Jon_Huntsman_Jr       0.80      0.96      0.87        45\n",
      "   Rick_Santorum       0.78      0.98      0.87        41\n",
      "    Gary_Johnson       1.00      1.00      1.00        39\n",
      "     Jim_Gilmore       0.95      0.95      0.95        38\n",
      "       Rand_Paul       0.62      0.86      0.72        37\n",
      "  Lincoln_Chafee       0.72      0.97      0.83        37\n",
      "George_Zimmerman       0.78      0.89      0.83        36\n",
      "  Lindsey_Graham       0.92      0.97      0.94        35\n",
      "\n",
      "       micro avg       0.80      0.95      0.87       422\n",
      "       macro avg       0.81      0.95      0.87       422\n",
      "    weighted avg       0.82      0.95      0.88       422\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the 10 most common classes in the dataset\n",
    "counts = dataset.count_values(\"ground_truth.detections.label\")\n",
    "classes_top10 = sorted(counts, key=counts.get, reverse=True)[:10]\n",
    "\n",
    "# Print a classification report for the top-10 classes\n",
    "results.print_report(classes=classes_top10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2743891904744837\n"
     ]
    }
   ],
   "source": [
    "print(results.mAP())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8523f57910d4626961ea372cd2ca161",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'customdata': array([0.91272851, 0.909137  , 0.90479841, 0.90406826, 0.90289347, …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot = results.plot_pr_curves(classes=[\"Shinzo_Abe\", \"Yoshihide_Suga\"])\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample = dataset.first()\n",
    "#print(sample['yolo-resnetv1-fcg_average_vote'].detections[0])\n",
    "#print(dataset.get_evaluation_info(\"eval\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute metadata so we can reference image height/width in our view\n",
    "dataset.compute_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.909090909090908"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(96**2 / 84480) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Create an expression that will match objects whose bounding boxes have\n",
    "# area less than 32^2 pixels\n",
    "#\n",
    "# Bounding box format is [top-left-x, top-left-y, width, height]\n",
    "# with relative coordinates in [0, 1], so we multiply by image\n",
    "# dimensions to get pixel area\n",
    "#\n",
    "bbox_area = (\n",
    "    F(\"$metadata.width\") * F(\"bounding_box\")[2] *\n",
    "    F(\"$metadata.height\") * F(\"bounding_box\")[3]\n",
    ")\n",
    "small_boxes = bbox_area < 32 ** 2\n",
    "#medium_boxes = (32 ** 2 < bbox_area) & (bbox_area < 96 ** 2)\n",
    "medium_boxes = (bbox_area >= 32 ** 2) & (bbox_area <= 96 ** 2)\n",
    "large_boxes = bbox_area > 96 ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4217329545454546, 0.21812499999999999, 0.14176136363636363, 0.27291666666666664]\n"
     ]
    }
   ],
   "source": [
    "#medium_boxes\n",
    "sample = dataset.first()\n",
    "print(sample.ground_truth.detections[0]['bounding_box'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating detections...\n",
      " 100% |███████████████| 1569/1569 [24.6s elapsed, 0s remaining, 72.5 samples/s]      \n",
      "Performing IoU sweep...\n",
      " 100% |███████████████| 1569/1569 [11.0s elapsed, 0s remaining, 156.1 samples/s]      \n",
      "Evaluating detections...\n",
      " 100% |███████████████| 6329/6329 [48.7s elapsed, 0s remaining, 148.5 samples/s]      \n",
      "Performing IoU sweep...\n",
      " 100% |███████████████| 6329/6329 [22.4s elapsed, 0s remaining, 308.5 samples/s]      \n",
      "Evaluating detections...\n",
      " 100% |█████████████████| 343/343 [2.3s elapsed, 0s remaining, 152.8 samples/s]      \n",
      "Performing IoU sweep...\n",
      " 100% |█████████████████| 343/343 [1.1s elapsed, 0s remaining, 311.0 samples/s]         \n"
     ]
    }
   ],
   "source": [
    "# Create a view that contains only small GT and predicted boxes\n",
    "small_boxes_eval_view = (\n",
    "    dataset\n",
    "    .filter_labels(\"ground_truth\", small_boxes)\n",
    "    .filter_labels(\"yolo-resnetv1-fcg_average_vote\", small_boxes)\n",
    "    .filter_labels(\"yolo-resnetv1-fcg_average_vote\", F(\"label\") != \"-1\")\n",
    ")\n",
    "medium_boxes_eval_view = (\n",
    "    dataset\n",
    "    .filter_labels(\"ground_truth\", medium_boxes)\n",
    "    .filter_labels(\"yolo-resnetv1-fcg_average_vote\", medium_boxes)\n",
    "    .filter_labels(\"yolo-resnetv1-fcg_average_vote\", F(\"label\") != \"-1\")    \n",
    ")\n",
    "large_boxes_eval_view = (\n",
    "    dataset\n",
    "    .filter_labels(\"ground_truth\", large_boxes)\n",
    "    .filter_labels(\"yolo-resnetv1-fcg_average_vote\", large_boxes)\n",
    "    .filter_labels(\"yolo-resnetv1-fcg_average_vote\", F(\"label\") != \"-1\")    \n",
    ")\n",
    "\n",
    "# Run evaluation\n",
    "small_boxes_results = small_boxes_eval_view.evaluate_detections(\n",
    "    \"yolo-resnetv1-fcg_average_vote\",\n",
    "    gt_field=\"ground_truth\",\n",
    "    eval_key=\"eval\",\n",
    "    compute_mAP=True,\n",
    ")\n",
    "medium_boxes_results = medium_boxes_eval_view.evaluate_detections(\n",
    "    \"yolo-resnetv1-fcg_average_vote\",\n",
    "    gt_field=\"ground_truth\",\n",
    "    eval_key=\"eval\",\n",
    "    compute_mAP=True,\n",
    ")\n",
    "large_boxes_results = large_boxes_eval_view.evaluate_detections(\n",
    "    \"yolo-resnetv1-fcg_average_vote\",\n",
    "    gt_field=\"ground_truth\",\n",
    "    eval_key=\"eval\",\n",
    "    compute_mAP=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Detections: {\n",
       "     'detections': BaseList([\n",
       "         <Detection: {\n",
       "             'id': '62aa9c95942ad79132de47e0',\n",
       "             'attributes': BaseDict({}),\n",
       "             'tags': BaseList([]),\n",
       "             'label': 'Yukio_Edano',\n",
       "             'bounding_box': BaseList([\n",
       "                 0.16676136363636365,\n",
       "                 0.49291666666666667,\n",
       "                 0.06079545454545454,\n",
       "                 0.115,\n",
       "             ]),\n",
       "             'mask': None,\n",
       "             'confidence': None,\n",
       "             'index': None,\n",
       "             'label_id': 'Edano',\n",
       "         }>,\n",
       "         <Detection: {\n",
       "             'id': '62aa9c95942ad79132de47e1',\n",
       "             'attributes': BaseDict({}),\n",
       "             'tags': BaseList([]),\n",
       "             'label': 'Toru_Hashimoto',\n",
       "             'bounding_box': BaseList([\n",
       "                 0.6762784090909091,\n",
       "                 0.5164583333333332,\n",
       "                 0.07187500000000001,\n",
       "                 0.12208333333333334,\n",
       "             ]),\n",
       "             'mask': None,\n",
       "             'confidence': None,\n",
       "             'index': None,\n",
       "             'label_id': 'Hashimoto',\n",
       "         }>,\n",
       "         <Detection: {\n",
       "             'id': '62aa9c95942ad79132de47e2',\n",
       "             'attributes': BaseDict({}),\n",
       "             'tags': BaseList([]),\n",
       "             'label': 'Kenji_Eda',\n",
       "             'bounding_box': BaseList([\n",
       "                 0.5830965909090909,\n",
       "                 0.5120833333333333,\n",
       "                 0.07755681818181819,\n",
       "                 0.12666666666666665,\n",
       "             ]),\n",
       "             'mask': None,\n",
       "             'confidence': None,\n",
       "             'index': None,\n",
       "             'label_id': 'Eda',\n",
       "         }>,\n",
       "         <Detection: {\n",
       "             'id': '62aa9c95942ad79132de47e3',\n",
       "             'attributes': BaseDict({}),\n",
       "             'tags': BaseList([]),\n",
       "             'label': 'Katsuya_Okada',\n",
       "             'bounding_box': BaseList([\n",
       "                 0.2629261363636364,\n",
       "                 0.5377083333333332,\n",
       "                 0.06789772727272726,\n",
       "                 0.12208333333333334,\n",
       "             ]),\n",
       "             'mask': None,\n",
       "             'confidence': None,\n",
       "             'index': None,\n",
       "             'label_id': 'Okada',\n",
       "         }>,\n",
       "     ]),\n",
       " }>,\n",
       " <Detections: {\n",
       "     'detections': BaseList([\n",
       "         <Detection: {\n",
       "             'id': '62aa9cc5942ad79132de7e24',\n",
       "             'attributes': BaseDict({}),\n",
       "             'tags': BaseList([]),\n",
       "             'label': 'Fumio_Kishida',\n",
       "             'bounding_box': BaseList([\n",
       "                 0.08352272727272726,\n",
       "                 0.26499999999999996,\n",
       "                 0.07670454545454546,\n",
       "                 0.13916666666666666,\n",
       "             ]),\n",
       "             'mask': None,\n",
       "             'confidence': None,\n",
       "             'index': None,\n",
       "             'label_id': 'Kishida',\n",
       "         }>,\n",
       "     ]),\n",
       " }>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_boxes_eval_view.bounds(\"ground_truth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "      Shinzo_Abe       0.99      0.83      0.90       558\n",
      "  Yoshihide_Suga       0.68      0.92      0.79       286\n",
      "        Taro_Aso       0.95      0.53      0.68       313\n",
      "   Fumio_Kishida       1.00      0.32      0.48       273\n",
      "     Yukio_Edano       0.56      0.31      0.40       378\n",
      "      Kazuo_Shii       0.66      0.67      0.67       372\n",
      "   Katsuya_Okada       0.86      0.66      0.75       195\n",
      " Yuichiro_Tamaki       0.80      0.75      0.78       287\n",
      "   Ichiro_Matsui       0.98      0.22      0.36       228\n",
      "Natsuo_Yamaguchi       0.89      0.41      0.56       262\n",
      "\n",
      "       micro avg       0.81      0.59      0.68      3152\n",
      "       macro avg       0.84      0.56      0.64      3152\n",
      "    weighted avg       0.83      0.59      0.66      3152\n",
      "\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "      Shinzo_Abe       0.99      0.84      0.91      1315\n",
      "  Yoshihide_Suga       0.94      0.99      0.96      1070\n",
      "        Taro_Aso       0.96      0.84      0.90       677\n",
      "   Fumio_Kishida       0.99      0.83      0.91       460\n",
      "     Yukio_Edano       0.73      0.92      0.82       271\n",
      "      Kazuo_Shii       0.81      1.00      0.90       294\n",
      "   Katsuya_Okada       1.00      0.80      0.89       353\n",
      " Yuichiro_Tamaki       0.93      0.98      0.96       299\n",
      "   Ichiro_Matsui       0.97      0.97      0.97       346\n",
      "Natsuo_Yamaguchi       0.94      0.96      0.95       247\n",
      "\n",
      "       micro avg       0.94      0.90      0.92      5332\n",
      "       macro avg       0.93      0.91      0.92      5332\n",
      "    weighted avg       0.95      0.90      0.92      5332\n",
      "\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "      Shinzo_Abe       1.00      0.98      0.99        61\n",
      "  Yoshihide_Suga       0.99      1.00      0.99        81\n",
      "        Taro_Aso       1.00      1.00      1.00        29\n",
      "   Fumio_Kishida       1.00      1.00      1.00        19\n",
      "     Yukio_Edano       1.00      1.00      1.00         6\n",
      "      Kazuo_Shii       0.00      0.00      0.00         0\n",
      "   Katsuya_Okada       0.00      0.00      0.00         0\n",
      " Yuichiro_Tamaki       1.00      1.00      1.00         2\n",
      "   Ichiro_Matsui       1.00      1.00      1.00         6\n",
      "Natsuo_Yamaguchi       1.00      1.00      1.00        18\n",
      "\n",
      "       micro avg       1.00      1.00      1.00       222\n",
      "       macro avg       0.80      0.80      0.80       222\n",
      "    weighted avg       1.00      1.00      1.00       222\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the 10 most common small object classes\n",
    "small_counts = small_boxes_eval_view.count_values(\"ground_truth.detections.label\")\n",
    "medium_counts = medium_boxes_eval_view.count_values(\"ground_truth.detections.label\")\n",
    "large_counts = large_boxes_eval_view.count_values(\"ground_truth.detections.label\")\n",
    "classes_top10_small = sorted(small_counts, key=counts.get, reverse=True)[:10]\n",
    "classes_top10_medium = sorted(medium_counts, key=counts.get, reverse=True)[:10]\n",
    "classes_top10_large = sorted(medium_counts, key=counts.get, reverse=True)[:10]\n",
    "\n",
    "# Print a classification report for the top-10 small object classes\n",
    "small_boxes_results.print_report(classes=classes_top10_small)\n",
    "medium_boxes_results.print_report(classes=classes_top10_medium)\n",
    "large_boxes_results.print_report(classes=classes_top10_large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd4bf80d943c49628b828ec0fcead54b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'mode': 'markers',\n",
       "              'opacity': 0.1,\n",
       "              'type': 'scatter',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Default behavior: only show rows (GT) for the requested classes, but include\n",
    "# \"other\" and \"missing\" columns that capture the rest of the predictions associated\n",
    "# with the GT labels of interest\n",
    "medium_boxes_results.plot_confusion_matrix(classes=classes_top10_medium)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd06865afcb545aea7a090873eff7093",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'customdata': array([0.91272851, 0.90504362, 0.90035601, 0.89917585, 0.8984457 , …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot = medium_boxes_results.plot_pr_curves(classes=[\"Shinzo_Abe\", \"Yoshihide_Suga\"])\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session launched. Run `session.show()` to open the App in a cell output.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "window.open('http://localhost:5151/');"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#session = fo.launch_app(dataset, auto=False)\n",
    "session = fo.launch_app(dataset, auto=False)\n",
    "session.open_tab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sort_by() got an unexpected keyword argument 'auto'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1445515/1170369057.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlarge_boxes_eval_view\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_by\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"eval_fp\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauto\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: sort_by() got an unexpected keyword argument 'auto'"
     ]
    }
   ],
   "source": [
    "session.view = large_boxes_eval_view.sort_by(\"eval_fp\", reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis for figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset_orig = fo.load_dataset(\"news7-lv\")\n",
    "dataset_orig.compute_metadata()\n",
    "# Do \"evaluate_detections\" to compute iou to be able to threshold wrt iou for US data evaluation\n",
    "# Important: do \"classwise=False\" to consider FNs\n",
    "#dataset_orig.evaluate_detections(\"yolo-resnetv1-fcg_average_vote\", \"ground_truth\", eval_key=\"eval\", classwise=False)\n",
    "\n",
    "# For NHK missing data\n",
    "years_list = [str(i) for i in range(2013, 2022)]\n",
    "view_analysis = dataset_orig.match(F(\"year\").is_in(years_list))\n",
    "\n",
    "# For US evaluation\n",
    "# Filter the detections based on the IoU threshold\n",
    "# So here was a funny bug that took me all the afternoon to find.\n",
    "# If you filter a dataset to a view object, and you compute the evaluation over that view, \n",
    "# weird things happen. I realised this after filtering by \"eval_iou\", that in a further step\n",
    "# it did not return anything when doing \"evaluate_detections\" some cells below.\n",
    "# To bypass this bug, convert a view to a dataset by using \"clone()\" once filtered by iou.\n",
    "#view_analysis = view_analysis.filter_labels(\"yolo-resnetv1-fcg_average_vote\", F(\"eval_iou\") > 0.001).clone()\n",
    "\n",
    "# Generate different views depending on the bounding box sizes \n",
    "bbox_area = (\n",
    "    F(\"$metadata.width\") * F(\"bounding_box\")[2] *\n",
    "    F(\"$metadata.height\") * F(\"bounding_box\")[3]\n",
    ")\n",
    "# [very small, small, small-medium, medium, medium-large, large, very large]\n",
    "# Average bbox for NHK = 78x78, HODO = 52x52. US dataset around 135 x 135.\n",
    "# Smallest NHK = 3x3, HODO = 2x2. US = 35x35\n",
    "# Largest NHK = 258x258, HODO = 174x174. US = 390x390\n",
    "\n",
    "boxes_areas = list(map(int, list(np.asarray([8, 16, 32, 64, 96, 128, 156]) ** 2)))\n",
    "boxes_filter_list = []\n",
    "\n",
    "for i in range(len(boxes_areas)):\n",
    "    if i == 0:\n",
    "        # Skip 0, used for posterior plots\n",
    "        boxes_filter = bbox_area <= boxes_areas[i]\n",
    "    else:\n",
    "        # Cases in the middle\n",
    "        boxes_filter = (bbox_area > boxes_areas[i-1]) & (bbox_area <= boxes_areas[i])\n",
    "\n",
    "    boxes_filter_list.append(boxes_filter)\n",
    "        \n",
    "# Last case\n",
    "boxes_filter_list.append(bbox_area > boxes_areas[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Generate views that contains only the filtered bboxes depending on size\n",
    "views_list = []\n",
    "\n",
    "for box_filter in boxes_filter_list:\n",
    "#for box_filter in [small_boxes, medium_boxes]:\n",
    "    view_filtered = (\n",
    "        view_analysis\n",
    "        .filter_labels(\"ground_truth\", box_filter)\n",
    "        .filter_labels(\"yolo-resnetv1-fcg_average_vote\", box_filter)\n",
    "        .filter_labels(\"yolo-resnetv1-fcg_average_vote\", F(\"label\") != \"-1\")\n",
    "    )\n",
    "    views_list.append(view_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating detections...\n",
      " 100% |█████████████████████| 0/0 [155.3ms elapsed, ? remaining, ? samples/s] \n",
      "Performing IoU sweep...\n",
      " 100% |█████████████████████| 0/0 [155.8ms elapsed, ? remaining, ? samples/s] \n",
      "Evaluating detections...\n",
      " 100% |█████████████████| 164/164 [1.5s elapsed, 0s remaining, 89.0 samples/s]          \n",
      "Performing IoU sweep...\n",
      " 100% |█████████████████| 164/164 [853.0ms elapsed, 0s remaining, 192.3 samples/s]      \n",
      "Evaluating detections...\n",
      " 100% |███████████████| 1224/1224 [16.8s elapsed, 0s remaining, 83.0 samples/s]       \n",
      "Performing IoU sweep...\n",
      " 100% |███████████████| 1224/1224 [7.5s elapsed, 0s remaining, 145.5 samples/s]      \n",
      "Evaluating detections...\n",
      " 100% |███████████████| 3582/3582 [30.0s elapsed, 0s remaining, 136.4 samples/s]      \n",
      "Performing IoU sweep...\n",
      "  25% |███\\-----------|  895/3582 [3.9s elapsed, 11.7s remaining, 241.6 samples/s]    "
     ]
    }
   ],
   "source": [
    "# Run evaluation for the generated filtered views\n",
    "results_list = []\n",
    "\n",
    "for view_filtered in views_list:\n",
    "    results_filtered = view_filtered.evaluate_detections(\n",
    "        \"yolo-resnetv1-fcg_average_vote\",\n",
    "        gt_field=\"ground_truth\",\n",
    "        eval_key=\"eval\",\n",
    "        compute_mAP=True,\n",
    "        #iou_threshs=[0.4, 0.45, 0.5, 0.55, 0.6],  # For US evaluation\n",
    "    )\n",
    "\n",
    "    results_list.append(results_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_df = []\n",
    "# 186**2 is for visualization purposes, representing [156-]\n",
    "for res, box_area in zip(results_list, boxes_areas + [186**2]):\n",
    "    res_map = round((max(res.mAP(), 0) * 100), 1)\n",
    "    res_f1 = round(res.metrics()['fscore'], 3)\n",
    "    box_size = int(np.sqrt(box_area))\n",
    "    rows_df.append([box_area, box_size, res_map, res_f1])\n",
    "    print(f\"mAP: {res_map}, F1: {res_f1}\")\n",
    "\n",
    "df_res = pd.DataFrame(data=rows_df, columns=['area', 'box_size', 'map', 'f1'])\n",
    "print(df_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# mAP\n",
    "fig = px.line(df_res, x=\"box_size\", y=\"map\", text=\"map\", title=f\"mAP per bounding box size for {dataset_orig.name}\")\n",
    "fig.update_traces(textposition=\"bottom right\")\n",
    "\n",
    "fig.update_xaxes(\n",
    "    title=\"Bounding box size\"\n",
    ")\n",
    "fig.update_yaxes(\n",
    "    title=\"mAP\"\n",
    ")\n",
    "\n",
    "fig.write_image(f\"/home/agirbau/work/politics/figures/results_map_face_size_{dataset_orig.name}.pdf\")\n",
    "fig.show()\n",
    "\n",
    "# F1 score\n",
    "fig = px.line(df_res, x=\"box_size\", y=\"f1\", text=\"f1\", title=f\"F-score per bounding box size for {dataset_orig.name}\")\n",
    "fig.update_traces(textposition=\"bottom right\")\n",
    "\n",
    "fig.update_xaxes(\n",
    "    title=\"Bounding box size\"\n",
    ")\n",
    "fig.update_yaxes(\n",
    "    title=\"F-score\"\n",
    ")\n",
    "\n",
    "fig.write_image(f\"/home/agirbau/work/politics/figures/results_f1_face_size_{dataset_orig.name}.pdf\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Create figure with secondary y-axis\n",
    "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "# Add traces\n",
    "# F-score\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=df_res[\"box_size\"],\n",
    "            y=df_res[\"f1\"], \n",
    "            text=df_res[\"f1\"], \n",
    "            name=\"F-score\", \n",
    "            mode=\"lines+markers+text\",\n",
    "            textposition=\"top left\"),\n",
    "    secondary_y=False,\n",
    ")\n",
    "# mAP\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=df_res[\"box_size\"],\n",
    "            y=df_res[\"map\"], \n",
    "            text=df_res[\"map\"], \n",
    "            name=\"mAP\", \n",
    "            mode=\"lines+markers+text\",\n",
    "            textposition=\"bottom right\"),\n",
    "    secondary_y=True,\n",
    ")\n",
    "\n",
    "# Add figure title\n",
    "fig.update_layout(\n",
    "    title_text=f\"F-score and mAP for {dataset_orig.name}\"\n",
    ")\n",
    "\n",
    "# Set x-axis title\n",
    "fig.update_xaxes(title_text=\"Bounding box size x size\")\n",
    "\n",
    "# Set y-axes titles\n",
    "fig.update_yaxes(title_text=\"<b>F-score</b>\", range=[-0.05, 1.1], secondary_y=False)\n",
    "fig.update_yaxes(title_text=\"<b>mAP</b>\", range=[-5, 110], secondary_y=True)\n",
    "\n",
    "fig.write_image(f\"/home/agirbau/work/politics/figures/results_f1_map_face_size_{dataset_orig.name}.pdf\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__delattr__', '__dir__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '_confusion_matrix', '_from_dict', '_get_class_index', '_get_iou_thresh_inds', '_parse_classes', '_prepare_serial_dict', 'attributes', 'confusion_matrix', 'copy', 'custom_attributes', 'from_dict', 'from_json', 'from_str', 'get_class_name', 'mAP', 'metrics', 'plot_confusion_matrix', 'plot_pr_curves', 'print_report', 'report', 'serialize', 'to_str', 'write_json']\n",
      "{'accuracy': 0.9489795918367347, 'precision': 0.9634185820653933, 'recall': 0.9844525305987429, 'fscore': 0.9738219895287957, 'support': 3023}\n"
     ]
    }
   ],
   "source": [
    "res = results_list[4]\n",
    "object_methods = [method_name for method_name in dir(res) if callable(getattr(res, method_name))]\n",
    "print(object_methods)\n",
    "print(res.metrics())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
